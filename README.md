# ğŸ¬ Sentiment Analysis with DistilBERT | Hugging Face + PyTorch

This project demonstrates how to perform real-time sentiment analysis using the `distilbert-base-uncased-finetuned-sst-2-english` transformer model from Hugging Face. It classifies input movie reviews as **Positive** or **Negative**, leveraging the power of pre-trained NLP models.

---

## ğŸš€ Why I Built This

As an aspiring AI/ML software engineer, I wanted to explore how production-ready NLP models work under the hood. This project helped me understand how to:

- Load and fine-tune Hugging Face transformers
- Tokenize and prepare raw text for model inference
- Work with PyTorch tensors and GPU acceleration
- Deploy fast, lightweight NLP pipelines

Iâ€™m passionate about building impactful AI systems â€” whether it's sentiment analysis, medical imaging, or agentic AI. This is one of several projects where I'm diving deeper into **language models and real-world inference pipelines**.

---

## ğŸ§  Model Overview

- **Model**: [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)
- **Dataset**: Stanford Sentiment Treebank (SST-2)
- **Framework**: PyTorch + Hugging Face Transformers

---

## ğŸ“¦ Tech Stack

- Python
- PyTorch
- Hugging Face Transformers
- Google Colab (for development)
- GitHub (version control)

---

## ğŸ–¥ï¸ How to Run

1. Clone the repository:

```bash
git clone https://github.com/smartha2003/sentiment-analysis-bert.git
cd sentiment-analysis-bert

